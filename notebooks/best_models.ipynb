{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:26:49.195431900Z",
     "start_time": "2026-01-29T08:26:48.623024700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- columns ---\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n",
      "--- Head of Dataset ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age           job  marital  education default  balance housing loan  \\\n0   58    management  married   tertiary      no     2143     yes   no   \n1   44    technician   single  secondary      no       29     yes   no   \n2   33  entrepreneur  married  secondary      no        2     yes  yes   \n3   47   blue-collar  married    unknown      no     1506     yes   no   \n4   33       unknown   single    unknown      no        1      no   no   \n\n   contact  day month  duration  campaign  pdays  previous poutcome   y  \n0  unknown    5   may       261         1     -1         0  unknown  no  \n1  unknown    5   may       151         1     -1         0  unknown  no  \n2  unknown    5   may        76         1     -1         0  unknown  no  \n3  unknown    5   may        92         1     -1         0  unknown  no  \n4  unknown    5   may       198         1     -1         0  unknown  no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2143</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>261</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>29</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>151</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>entrepreneur</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>76</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1506</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>92</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>unknown</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>198</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Info of Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "None\n",
      "\n",
      "--- Describe of Dataset ---\n",
      "                age        balance           day      duration      campaign  \\\n",
      "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
      "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
      "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
      "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
      "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
      "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
      "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
      "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
      "\n",
      "              pdays      previous  \n",
      "count  45211.000000  45211.000000  \n",
      "mean      40.197828      0.580323  \n",
      "std      100.128746      2.303441  \n",
      "min       -1.000000      0.000000  \n",
      "25%       -1.000000      0.000000  \n",
      "50%       -1.000000      0.000000  \n",
      "75%       -1.000000      0.000000  \n",
      "max      871.000000    275.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'bank-full.csv',\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    engine='python'\n",
    ")\n",
    "print(\"--- columns ---\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"--- Head of Dataset ---\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n--- Info of Dataset ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Describe of Dataset ---\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n",
      "Missing values per column:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Shape after outlier handling: (44724, 17)\n",
      "Final shape: (44724, 43)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        age   balance       day  duration  campaign  previous  y  \\\n0  1.749275  0.392786 -1.298868  0.031546 -0.645438 -0.363878  0   \n1  0.346205 -0.552943 -1.298868 -0.437198 -0.645438 -0.363878  0   \n2 -0.756207 -0.565022 -1.298868 -0.756795 -0.645438 -0.363878  0   \n3  0.646863  0.107814 -1.298868 -0.688615 -0.645438 -0.363878  0   \n4 -0.756207 -0.565470 -1.298868 -0.236916 -0.645438 -0.363878  0   \n\n   pdays_contacted  job_blue-collar  job_entrepreneur  ...  month_jul  \\\n0                0                0                 0  ...          0   \n1                0                0                 0  ...          0   \n2                0                0                 1  ...          0   \n3                0                1                 0  ...          0   \n4                0                0                 0  ...          0   \n\n   month_jun  month_mar  month_may  month_nov  month_oct  month_sep  \\\n0          0          0          1          0          0          0   \n1          0          0          1          0          0          0   \n2          0          0          1          0          0          0   \n3          0          0          1          0          0          0   \n4          0          0          1          0          0          0   \n\n   poutcome_other  poutcome_success  poutcome_unknown  \n0               0                 0                 1  \n1               0                 0                 1  \n2               0                 0                 1  \n3               0                 0                 1  \n4               0                 0                 1  \n\n[5 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>balance</th>\n      <th>day</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>previous</th>\n      <th>y</th>\n      <th>pdays_contacted</th>\n      <th>job_blue-collar</th>\n      <th>job_entrepreneur</th>\n      <th>...</th>\n      <th>month_jul</th>\n      <th>month_jun</th>\n      <th>month_mar</th>\n      <th>month_may</th>\n      <th>month_nov</th>\n      <th>month_oct</th>\n      <th>month_sep</th>\n      <th>poutcome_other</th>\n      <th>poutcome_success</th>\n      <th>poutcome_unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.749275</td>\n      <td>0.392786</td>\n      <td>-1.298868</td>\n      <td>0.031546</td>\n      <td>-0.645438</td>\n      <td>-0.363878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.346205</td>\n      <td>-0.552943</td>\n      <td>-1.298868</td>\n      <td>-0.437198</td>\n      <td>-0.645438</td>\n      <td>-0.363878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.756207</td>\n      <td>-0.565022</td>\n      <td>-1.298868</td>\n      <td>-0.756795</td>\n      <td>-0.645438</td>\n      <td>-0.363878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.646863</td>\n      <td>0.107814</td>\n      <td>-1.298868</td>\n      <td>-0.688615</td>\n      <td>-0.645438</td>\n      <td>-0.363878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.756207</td>\n      <td>-0.565470</td>\n      <td>-1.298868</td>\n      <td>-0.236916</td>\n      <td>-0.645438</td>\n      <td>-0.363878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 43 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Copy dataset (safe practice)\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove duplicate rows\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Handle outliers (SAFE strategy)\n",
    "# 1. IQR-based removal ONLY for safe variables\n",
    "safe_outlier_cols = ['age', 'day']\n",
    "\n",
    "for col in safe_outlier_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "\n",
    "# 2. Winsorization (clipping) for financial / behavioral variables\n",
    "winsor_cols = ['balance', 'duration', 'campaign', 'previous']\n",
    "\n",
    "for col in winsor_cols:\n",
    "    lower = df_clean[col].quantile(0.01)\n",
    "    upper = df_clean[col].quantile(0.99)\n",
    "    df_clean[col] = df_clean[col].clip(lower, upper)\n",
    "\n",
    "print(\"Shape after outlier handling:\", df_clean.shape)\n",
    "\n",
    "# Handle special value pdays = -1\n",
    "df_clean['pdays_contacted'] = df_clean['pdays'].apply(\n",
    "    lambda x: 0 if x == -1 else 1\n",
    ")\n",
    "df_clean.drop(columns=['pdays'], inplace=True)\n",
    "\n",
    "# Encode target variable\n",
    "df_clean['y'] = df_clean['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "df_encoded = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Convert boolean columns to int\n",
    "bool_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "num_features = [\n",
    "    'age', 'balance', 'day',\n",
    "    'duration', 'campaign', 'previous'\n",
    "]\n",
    "\n",
    "df_encoded[num_features] = scaler.fit_transform(\n",
    "    df_encoded[num_features]\n",
    ")\n",
    "\n",
    "# Final check\n",
    "print(\"Final shape:\", df_encoded.shape)\n",
    "display(df_encoded.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:27:11.388625400Z",
     "start_time": "2026-01-29T08:27:11.055832200Z"
    }
   },
   "id": "cae2508f04e35f4b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (35779, 42)\n",
      "Test shape: (8945, 42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split features and target\n",
    "X = df_encoded.drop(columns=['y'])\n",
    "y = df_encoded['y']\n",
    "\n",
    "# Train / Test Split (80 / 20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=17,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:27:25.857764200Z",
     "start_time": "2026-01-29T08:27:25.738295300Z"
    }
   },
   "id": "110442f922f2b73f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:30:16.723140300Z",
     "start_time": "2026-01-29T08:30:16.704439600Z"
    }
   },
   "id": "a91d2aaeac517d4b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (RF): 0.9065399664617104\n",
      "\n",
      "Classification Report (RF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7931\n",
      "           1       0.59      0.58      0.59      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.77      0.77      0.77      8945\n",
      "weighted avg       0.91      0.91      0.91      8945\n",
      "\n",
      "Confusion Matrix (RF):\n",
      " [[7518  413]\n",
      " [ 423  591]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=7,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy (RF):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report (RF):\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix (RF):\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "with open(\"rf_model_best.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:35:47.883699600Z",
     "start_time": "2026-01-29T08:35:46.639499400Z"
    }
   },
   "id": "cdfe736bd724e59b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (SVM): 0.8489659027389603\n",
      "\n",
      "Classification Report (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      7931\n",
      "           1       0.42      0.86      0.56      1014\n",
      "\n",
      "    accuracy                           0.85      8945\n",
      "   macro avg       0.70      0.85      0.74      8945\n",
      "weighted avg       0.92      0.85      0.87      8945\n",
      "\n",
      "Confusion Matrix (SVM):\n",
      " [[6724 1207]\n",
      " [ 144  870]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_svm = scaler.fit_transform(X_train)\n",
    "X_test_svm  = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(\n",
    "    C=1,\n",
    "    gamma='scale',\n",
    "    kernel='rbf',\n",
    "    probability=True,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm.fit(X_train_svm, y_train)\n",
    "y_pred = svm.predict(X_test_svm)\n",
    "\n",
    "print(\"Test Accuracy (SVM):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report (SVM):\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix (SVM):\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "pickle.dump(svm, open(\"svm_model.pkl\", \"wb\"))\n",
    "pickle.dump(scaler, open(\"svm_scaler.pkl\", \"wb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:44:33.569993500Z",
     "start_time": "2026-01-29T08:37:22.189199Z"
    }
   },
   "id": "feed951323445682"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (MLP - 1 Layer): 0.9081050866405813\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      7931\n",
      "           1       0.62      0.48      0.54      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.78      0.72      0.75      8945\n",
      "weighted avg       0.90      0.91      0.90      8945\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7637  294]\n",
      " [ 528  486]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_mlp = scaler.fit_transform(X_train)\n",
    "X_test_mlp  = scaler.transform(X_test)\n",
    "\n",
    "mlp_1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(32,),\n",
    "    activation='relu',\n",
    "    alpha=0.01,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_1.fit(X_train_mlp, y_train)\n",
    "y_pred = mlp_1.predict(X_test_mlp)\n",
    "\n",
    "print(\"Test Accuracy (MLP - 1 Layer):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "pickle.dump(mlp_1, open(\"mlp_1layer.pkl\", \"wb\"))\n",
    "pickle.dump(scaler, open(\"mlp_scaler.pkl\", \"wb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:44:45.841959600Z",
     "start_time": "2026-01-29T08:44:33.567718800Z"
    }
   },
   "id": "72cdded30b554671"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (MLP - 2 Layers): 0.9025153717160425\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      7931\n",
      "           1       0.57      0.56      0.57      1014\n",
      "\n",
      "    accuracy                           0.90      8945\n",
      "   macro avg       0.76      0.75      0.76      8945\n",
      "weighted avg       0.90      0.90      0.90      8945\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7503  428]\n",
      " [ 444  570]]\n"
     ]
    }
   ],
   "source": [
    "mlp_2 = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    alpha=0.01,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=400,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_2.fit(X_train_mlp, y_train)\n",
    "y_pred = mlp_2.predict(X_test_mlp)\n",
    "\n",
    "print(\"Test Accuracy (MLP - 2 Layers):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "pickle.dump(mlp_2, open(\"mlp_2layer.pkl\", \"wb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:45:09.667534400Z",
     "start_time": "2026-01-29T08:44:45.841959600Z"
    }
   },
   "id": "41310a1c25232e3c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1502718 into shape (43,1)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m X_train_scaled = scaler.fit_transform(X_train)\n\u001B[32m      8\u001B[39m X_test_scaled  = scaler.transform(X_test)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m X_train_cnn = \u001B[43mX_train_scaled\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m43\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m X_test_cnn  = X_test_scaled.reshape(-\u001B[32m1\u001B[39m, \u001B[32m43\u001B[39m, \u001B[32m1\u001B[39m)\n\u001B[32m     13\u001B[39m cnn_2 = Sequential([\n\u001B[32m     14\u001B[39m     Conv1D(\u001B[32m32\u001B[39m, \u001B[32m3\u001B[39m, activation=\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, input_shape=(\u001B[32m43\u001B[39m, \u001B[32m1\u001B[39m)),\n\u001B[32m     15\u001B[39m     MaxPooling1D(\u001B[32m2\u001B[39m),\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     Dense(\u001B[32m1\u001B[39m, activation=\u001B[33m'\u001B[39m\u001B[33msigmoid\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     24\u001B[39m ])\n",
      "\u001B[31mValueError\u001B[39m: cannot reshape array of size 1502718 into shape (43,1)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_cnn = X_train_scaled.reshape(-1, 43, 1)\n",
    "X_test_cnn  = X_test_scaled.reshape(-1, 43, 1)\n",
    "\n",
    "cnn_2 = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(43, 1)),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_2.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_2.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = (cnn_2.predict(X_test_cnn) > 0.5).astype(int)\n",
    "\n",
    "print(\"Test Accuracy (CNN - 2 Layers):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "cnn_2.save(\"cnn_2layer.h5\")\n",
    "pickle.dump(scaler, open(\"cnn_scaler.pkl\", \"wb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:50:08.032259300Z",
     "start_time": "2026-01-29T08:50:07.920045700Z"
    }
   },
   "id": "c6ff4d64c950db1f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khank\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m      1\u001B[39m cnn_1 = Sequential([\n\u001B[32m      2\u001B[39m     Conv1D(\u001B[32m64\u001B[39m, \u001B[32m3\u001B[39m, activation=\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, input_shape=(\u001B[32m43\u001B[39m, \u001B[32m1\u001B[39m)),\n\u001B[32m      3\u001B[39m     MaxPooling1D(\u001B[32m2\u001B[39m),\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m     Dense(\u001B[32m1\u001B[39m, activation=\u001B[33m'\u001B[39m\u001B[33msigmoid\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      9\u001B[39m ])\n\u001B[32m     11\u001B[39m cnn_1.compile(\n\u001B[32m     12\u001B[39m     optimizer=Adam(learning_rate=\u001B[32m0.001\u001B[39m),\n\u001B[32m     13\u001B[39m     loss=\u001B[33m'\u001B[39m\u001B[33mbinary_crossentropy\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     14\u001B[39m     metrics=[\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     15\u001B[39m )\n\u001B[32m     17\u001B[39m cnn_1.fit(\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     \u001B[43mX_train_cnn\u001B[49m, y_train,\n\u001B[32m     19\u001B[39m     epochs=\u001B[32m100\u001B[39m,\n\u001B[32m     20\u001B[39m     batch_size=\u001B[32m64\u001B[39m,\n\u001B[32m     21\u001B[39m     validation_split=\u001B[32m0.2\u001B[39m,\n\u001B[32m     22\u001B[39m     verbose=\u001B[32m1\u001B[39m\n\u001B[32m     23\u001B[39m )\n\u001B[32m     25\u001B[39m y_pred = (cnn_1.predict(X_test_cnn) > \u001B[32m0.5\u001B[39m).astype(\u001B[38;5;28mint\u001B[39m)\n\u001B[32m     27\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTest Accuracy (CNN - 1 Layer):\u001B[39m\u001B[33m\"\u001B[39m, accuracy_score(y_test, y_pred))\n",
      "\u001B[31mNameError\u001B[39m: name 'X_train_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_1 = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(43, 1)),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_1.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_1.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = (cnn_1.predict(X_test_cnn) > 0.5).astype(int)\n",
    "\n",
    "print(\"Test Accuracy (CNN - 1 Layer):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "cnn_1.save(\"cnn_1layer.h5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-29T08:50:09.563960800Z",
     "start_time": "2026-01-29T08:50:09.127301700Z"
    }
   },
   "id": "bbaef14aa1d23928"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1415973308cc4f26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
