{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d90c2c5-23c4-401c-9e66-40bb8005fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- columns ---\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n",
      "--- Head of Dataset ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Info of Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "None\n",
      "\n",
      "--- Describe of Dataset ---\n",
      "                age        balance           day      duration      campaign  \\\n",
      "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
      "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
      "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
      "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
      "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
      "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
      "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
      "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
      "\n",
      "              pdays      previous  \n",
      "count  45211.000000  45211.000000  \n",
      "mean      40.197828      0.580323  \n",
      "std      100.128746      2.303441  \n",
      "min       -1.000000      0.000000  \n",
      "25%       -1.000000      0.000000  \n",
      "50%       -1.000000      0.000000  \n",
      "75%       -1.000000      0.000000  \n",
      "max      871.000000    275.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'bank-full.csv',\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    engine='python'\n",
    ")\n",
    "print(\"--- columns ---\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"--- Head of Dataset ---\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n--- Info of Dataset ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Describe of Dataset ---\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9937b1-5f8c-429d-a5cd-349b72de5b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n",
      "Missing values per column:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Shape after outlier handling: (44724, 17)\n",
      "Final shape: (44724, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>pdays_contacted</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.749275</td>\n",
       "      <td>0.392786</td>\n",
       "      <td>-1.298868</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.346205</td>\n",
       "      <td>-0.552943</td>\n",
       "      <td>-1.298868</td>\n",
       "      <td>-0.437198</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.756207</td>\n",
       "      <td>-0.565022</td>\n",
       "      <td>-1.298868</td>\n",
       "      <td>-0.756795</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646863</td>\n",
       "      <td>0.107814</td>\n",
       "      <td>-1.298868</td>\n",
       "      <td>-0.688615</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.756207</td>\n",
       "      <td>-0.565470</td>\n",
       "      <td>-1.298868</td>\n",
       "      <td>-0.236916</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   balance       day  duration  campaign  previous  y  \\\n",
       "0  1.749275  0.392786 -1.298868  0.031546 -0.645438 -0.363878  0   \n",
       "1  0.346205 -0.552943 -1.298868 -0.437198 -0.645438 -0.363878  0   \n",
       "2 -0.756207 -0.565022 -1.298868 -0.756795 -0.645438 -0.363878  0   \n",
       "3  0.646863  0.107814 -1.298868 -0.688615 -0.645438 -0.363878  0   \n",
       "4 -0.756207 -0.565470 -1.298868 -0.236916 -0.645438 -0.363878  0   \n",
       "\n",
       "   pdays_contacted  job_blue-collar  job_entrepreneur  ...  month_jul  \\\n",
       "0                0                0                 0  ...          0   \n",
       "1                0                0                 0  ...          0   \n",
       "2                0                0                 1  ...          0   \n",
       "3                0                1                 0  ...          0   \n",
       "4                0                0                 0  ...          0   \n",
       "\n",
       "   month_jun  month_mar  month_may  month_nov  month_oct  month_sep  \\\n",
       "0          0          0          1          0          0          0   \n",
       "1          0          0          1          0          0          0   \n",
       "2          0          0          1          0          0          0   \n",
       "3          0          0          1          0          0          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  \n",
       "0               0                 0                 1  \n",
       "1               0                 0                 1  \n",
       "2               0                 0                 1  \n",
       "3               0                 0                 1  \n",
       "4               0                 0                 1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Copy dataset (safe practice)\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove duplicate rows\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Handle outliers (SAFE strategy)\n",
    "# 1. IQR-based removal ONLY for safe variables\n",
    "safe_outlier_cols = ['age', 'day']\n",
    "\n",
    "for col in safe_outlier_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "\n",
    "# 2. Winsorization (clipping) for financial / behavioral variables\n",
    "winsor_cols = ['balance', 'duration', 'campaign', 'previous']\n",
    "\n",
    "for col in winsor_cols:\n",
    "    lower = df_clean[col].quantile(0.01)\n",
    "    upper = df_clean[col].quantile(0.99)\n",
    "    df_clean[col] = df_clean[col].clip(lower, upper)\n",
    "\n",
    "print(\"Shape after outlier handling:\", df_clean.shape)\n",
    "\n",
    "# Handle special value pdays = -1\n",
    "df_clean['pdays_contacted'] = df_clean['pdays'].apply(\n",
    "    lambda x: 0 if x == -1 else 1\n",
    ")\n",
    "df_clean.drop(columns=['pdays'], inplace=True)\n",
    "\n",
    "# Encode target variable\n",
    "df_clean['y'] = df_clean['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "df_encoded = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Convert boolean columns to int\n",
    "bool_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "num_features = [\n",
    "    'age', 'balance', 'day',\n",
    "    'duration', 'campaign', 'previous'\n",
    "]\n",
    "\n",
    "df_encoded[num_features] = scaler.fit_transform(\n",
    "    df_encoded[num_features]\n",
    ")\n",
    "\n",
    "# Final check\n",
    "print(\"Final shape:\", df_encoded.shape)\n",
    "display(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36954ade-a469-46ab-bf0b-97c85e337153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (35779, 42)\n",
      "Test shape: (8945, 42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split features and target\n",
    "X = df_encoded.drop(columns=['y'])\n",
    "y = df_encoded['y']\n",
    "\n",
    "# Train / Test Split (80 / 20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=17,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7920c0d2-0514-47a5-9fe3-15e2024b84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (35779, 42)\n",
      "Test shape: (8945, 42)\n",
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
      "Best Hyperparameters:\n",
      "{'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 100}\n",
      "\n",
      "Test Accuracy: 0.9104527669088877\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      7931\n",
      "           1       0.68      0.40      0.50      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.80      0.69      0.73      8945\n",
      "weighted avg       0.90      0.91      0.90      8945\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7741  190]\n",
      " [ 611  403]]\n",
      "\n",
      "Best Random Forest model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=17,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100, 150],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 7, 10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluation on Test Set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save Best Model\n",
    "joblib.dump(best_rf, \"best_random_forest_model.pkl\")\n",
    "\n",
    "print(\"\\nBest Random Forest model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07df3681-c366-4bbd-ac84-08a312bee473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Hyperparameters (SVM):\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Test Accuracy (SVM): 0.9064281721632197\n",
      "\n",
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      7931\n",
      "           1       0.66      0.35      0.46      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.79      0.67      0.70      8945\n",
      "weighted avg       0.89      0.91      0.89      8945\n",
      "\n",
      "\n",
      "Confusion Matrix (SVM):\n",
      "[[7750  181]\n",
      " [ 656  358]]\n",
      "\n",
      "Best SVM model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(\n",
    "    probability=True,   # needed for ROC / probability analysis later\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters (SVM):\")\n",
    "print(grid_search_svm.best_params_)\n",
    "\n",
    "# Evaluation on Test Set\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Accuracy (SVM):\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nConfusion Matrix (SVM):\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# Save Best Model\n",
    "joblib.dump(best_svm, \"best_svm_model.pkl\")\n",
    "\n",
    "print(\"\\nBest SVM model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf57eff3-aa3c-4be1-b229-5ef8ac096ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Hyperparameters (MLP - 1 Layer):\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (32,), 'learning_rate_init': 0.001}\n",
      "\n",
      "Test Accuracy (MLP - 1 Layer): 0.9126886528787032\n",
      "\n",
      "Classification Report (MLP - 1 Layer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7931\n",
      "           1       0.66      0.46      0.55      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.80      0.72      0.75      8945\n",
      "weighted avg       0.90      0.91      0.91      8945\n",
      "\n",
      "\n",
      "Confusion Matrix (MLP - 1 Layer):\n",
      "[[7693  238]\n",
      " [ 543  471]]\n",
      "\n",
      "Best MLP (1 Layer) model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khank\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "mlp_1layer = MLPClassifier(\n",
    "    max_iter=200,\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# گرید سرچ\n",
    "param_grid_1layer = {\n",
    "    'hidden_layer_sizes': [(32,), (64,), (128,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_mlp_1layer = GridSearchCV(\n",
    "    mlp_1layer,\n",
    "    param_grid_1layer,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_mlp_1layer.fit(X_train, y_train)\n",
    "\n",
    "best_mlp_1layer = grid_mlp_1layer.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters (MLP - 1 Layer):\")\n",
    "print(grid_mlp_1layer.best_params_)\n",
    "\n",
    "y_pred = best_mlp_1layer.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Accuracy (MLP - 1 Layer):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report (MLP - 1 Layer):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix (MLP - 1 Layer):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "joblib.dump(best_mlp_1layer, \"best_mlp_1layer.pkl\")\n",
    "print(\"\\nBest MLP (1 Layer) model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed38954-3d59-402c-b014-c5bc5ab828e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Hyperparameters (MLP - 2 Layers):\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (128, 32), 'learning_rate_init': 0.01}\n",
      "\n",
      "Test Accuracy (MLP - 2 Layers): 0.8990497484628284\n",
      "\n",
      "Classification Report (MLP - 2 Layers):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      7931\n",
      "           1       0.55      0.57      0.56      1014\n",
      "\n",
      "    accuracy                           0.90      8945\n",
      "   macro avg       0.75      0.76      0.75      8945\n",
      "weighted avg       0.90      0.90      0.90      8945\n",
      "\n",
      "\n",
      "Confusion Matrix (MLP - 2 Layers):\n",
      "[[7464  467]\n",
      " [ 436  578]]\n",
      "\n",
      "Best MLP (2 Layers) model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "mlp_2layer = MLPClassifier(\n",
    "    max_iter=300,\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "param_grid_2layer = {\n",
    "    'hidden_layer_sizes': [(64, 32), (128, 64), (128, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_mlp_2layer = GridSearchCV(\n",
    "    mlp_2layer,\n",
    "    param_grid_2layer,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_mlp_2layer.fit(X_train, y_train)\n",
    "\n",
    "best_mlp_2layer = grid_mlp_2layer.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters (MLP - 2 Layers):\")\n",
    "print(grid_mlp_2layer.best_params_)\n",
    "\n",
    "y_pred = best_mlp_2layer.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Accuracy (MLP - 2 Layers):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report (MLP - 2 Layers):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix (MLP - 2 Layers):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "joblib.dump(best_mlp_2layer, \"best_mlp_2layer.pkl\")\n",
    "print(\"\\nBest MLP (2 Layers) model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631008ef-1c0e-4608-b973-4ec97772f41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khank\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.8874 - loss: 0.2816 - val_accuracy: 0.8985 - val_loss: 0.2244\n",
      "Epoch 2/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9055 - loss: 0.2224 - val_accuracy: 0.8994 - val_loss: 0.2196\n",
      "Epoch 3/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9044 - loss: 0.2166 - val_accuracy: 0.9011 - val_loss: 0.2155\n",
      "Epoch 4/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9062 - loss: 0.2132 - val_accuracy: 0.9002 - val_loss: 0.2126\n",
      "Epoch 5/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9073 - loss: 0.2135 - val_accuracy: 0.9027 - val_loss: 0.2114\n",
      "Epoch 6/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9095 - loss: 0.2036 - val_accuracy: 0.9039 - val_loss: 0.2085\n",
      "Epoch 7/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9076 - loss: 0.2083 - val_accuracy: 0.9058 - val_loss: 0.2059\n",
      "Epoch 8/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9087 - loss: 0.2064 - val_accuracy: 0.9011 - val_loss: 0.2050\n",
      "Epoch 9/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9070 - loss: 0.2081 - val_accuracy: 0.9055 - val_loss: 0.2042\n",
      "Epoch 10/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9089 - loss: 0.2032 - val_accuracy: 0.9033 - val_loss: 0.2033\n",
      "Epoch 11/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9052 - loss: 0.2109 - val_accuracy: 0.9041 - val_loss: 0.2090\n",
      "Epoch 12/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9112 - loss: 0.2029 - val_accuracy: 0.9050 - val_loss: 0.2022\n",
      "Epoch 13/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9100 - loss: 0.2015 - val_accuracy: 0.9019 - val_loss: 0.2033\n",
      "Epoch 14/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9123 - loss: 0.1982 - val_accuracy: 0.9058 - val_loss: 0.2048\n",
      "Epoch 15/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9115 - loss: 0.1976 - val_accuracy: 0.9022 - val_loss: 0.2040\n",
      "Epoch 16/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9135 - loss: 0.1937 - val_accuracy: 0.9030 - val_loss: 0.2027\n",
      "Epoch 17/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9114 - loss: 0.1958 - val_accuracy: 0.9041 - val_loss: 0.2032\n",
      "Epoch 18/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9090 - loss: 0.2043 - val_accuracy: 0.9022 - val_loss: 0.2029\n",
      "Epoch 19/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9108 - loss: 0.1968 - val_accuracy: 0.9013 - val_loss: 0.2025\n",
      "Epoch 20/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9145 - loss: 0.1913 - val_accuracy: 0.9044 - val_loss: 0.2018\n",
      "Epoch 21/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9122 - loss: 0.1975 - val_accuracy: 0.9027 - val_loss: 0.2012\n",
      "Epoch 22/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9129 - loss: 0.1900 - val_accuracy: 0.9030 - val_loss: 0.1997\n",
      "Epoch 23/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9148 - loss: 0.1924 - val_accuracy: 0.9022 - val_loss: 0.2035\n",
      "Epoch 24/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9110 - loss: 0.1966 - val_accuracy: 0.9039 - val_loss: 0.2009\n",
      "Epoch 25/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9125 - loss: 0.1904 - val_accuracy: 0.9036 - val_loss: 0.2010\n",
      "Epoch 26/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9154 - loss: 0.1914 - val_accuracy: 0.9016 - val_loss: 0.2027\n",
      "Epoch 27/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9146 - loss: 0.1879 - val_accuracy: 0.9036 - val_loss: 0.2021\n",
      "Epoch 28/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9141 - loss: 0.1938 - val_accuracy: 0.9022 - val_loss: 0.2016\n",
      "Epoch 29/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9146 - loss: 0.1856 - val_accuracy: 0.9033 - val_loss: 0.2004\n",
      "Epoch 30/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9154 - loss: 0.1905 - val_accuracy: 0.9033 - val_loss: 0.2006\n",
      "Epoch 31/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9150 - loss: 0.1910 - val_accuracy: 0.9075 - val_loss: 0.2004\n",
      "Epoch 32/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9156 - loss: 0.1893 - val_accuracy: 0.9041 - val_loss: 0.2005\n",
      "Epoch 33/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9132 - loss: 0.1916 - val_accuracy: 0.9041 - val_loss: 0.2001\n",
      "Epoch 34/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9137 - loss: 0.1875 - val_accuracy: 0.9044 - val_loss: 0.2004\n",
      "Epoch 35/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9168 - loss: 0.1868 - val_accuracy: 0.9064 - val_loss: 0.1998\n",
      "Epoch 36/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9131 - loss: 0.1952 - val_accuracy: 0.9061 - val_loss: 0.2043\n",
      "Epoch 37/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9143 - loss: 0.1873 - val_accuracy: 0.9019 - val_loss: 0.2019\n",
      "Epoch 38/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9141 - loss: 0.1902 - val_accuracy: 0.9025 - val_loss: 0.2038\n",
      "Epoch 39/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9134 - loss: 0.1902 - val_accuracy: 0.9030 - val_loss: 0.2039\n",
      "Epoch 40/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9152 - loss: 0.1895 - val_accuracy: 0.9050 - val_loss: 0.2020\n",
      "Epoch 41/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9158 - loss: 0.1860 - val_accuracy: 0.9072 - val_loss: 0.1993\n",
      "Epoch 42/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9149 - loss: 0.1894 - val_accuracy: 0.9036 - val_loss: 0.2022\n",
      "Epoch 43/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9149 - loss: 0.1881 - val_accuracy: 0.9058 - val_loss: 0.2013\n",
      "Epoch 44/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9174 - loss: 0.1854 - val_accuracy: 0.9092 - val_loss: 0.2016\n",
      "Epoch 45/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9147 - loss: 0.1887 - val_accuracy: 0.9089 - val_loss: 0.1990\n",
      "Epoch 46/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9160 - loss: 0.1880 - val_accuracy: 0.9061 - val_loss: 0.2012\n",
      "Epoch 47/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9157 - loss: 0.1886 - val_accuracy: 0.9061 - val_loss: 0.2011\n",
      "Epoch 48/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9161 - loss: 0.1854 - val_accuracy: 0.9053 - val_loss: 0.2020\n",
      "Epoch 49/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9184 - loss: 0.1822 - val_accuracy: 0.9030 - val_loss: 0.2048\n",
      "Epoch 50/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9192 - loss: 0.1796 - val_accuracy: 0.9016 - val_loss: 0.2024\n",
      "Epoch 51/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9163 - loss: 0.1837 - val_accuracy: 0.9069 - val_loss: 0.2007\n",
      "Epoch 52/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9184 - loss: 0.1845 - val_accuracy: 0.9069 - val_loss: 0.2012\n",
      "Epoch 53/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9163 - loss: 0.1849 - val_accuracy: 0.9047 - val_loss: 0.2036\n",
      "Epoch 54/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9139 - loss: 0.1873 - val_accuracy: 0.9039 - val_loss: 0.2040\n",
      "Epoch 55/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9177 - loss: 0.1828 - val_accuracy: 0.9061 - val_loss: 0.2044\n",
      "Epoch 56/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9175 - loss: 0.1827 - val_accuracy: 0.9067 - val_loss: 0.2038\n",
      "Epoch 57/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9169 - loss: 0.1858 - val_accuracy: 0.9055 - val_loss: 0.2026\n",
      "Epoch 58/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9196 - loss: 0.1808 - val_accuracy: 0.9002 - val_loss: 0.2048\n",
      "Epoch 59/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9183 - loss: 0.1821 - val_accuracy: 0.9061 - val_loss: 0.2045\n",
      "Epoch 60/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9180 - loss: 0.1829 - val_accuracy: 0.9055 - val_loss: 0.2042\n",
      "Epoch 61/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9174 - loss: 0.1800 - val_accuracy: 0.9044 - val_loss: 0.2037\n",
      "Epoch 62/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9201 - loss: 0.1814 - val_accuracy: 0.9067 - val_loss: 0.2024\n",
      "Epoch 63/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9194 - loss: 0.1796 - val_accuracy: 0.9053 - val_loss: 0.2033\n",
      "Epoch 64/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9198 - loss: 0.1830 - val_accuracy: 0.9053 - val_loss: 0.2049\n",
      "Epoch 65/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1775 - val_accuracy: 0.9050 - val_loss: 0.2066\n",
      "Epoch 66/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9187 - loss: 0.1813 - val_accuracy: 0.9047 - val_loss: 0.2029\n",
      "Epoch 67/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9162 - loss: 0.1863 - val_accuracy: 0.9016 - val_loss: 0.2043\n",
      "Epoch 68/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9197 - loss: 0.1805 - val_accuracy: 0.9053 - val_loss: 0.2038\n",
      "Epoch 69/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9204 - loss: 0.1807 - val_accuracy: 0.9078 - val_loss: 0.2037\n",
      "Epoch 70/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9182 - loss: 0.1788 - val_accuracy: 0.9072 - val_loss: 0.2028\n",
      "Epoch 71/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9205 - loss: 0.1749 - val_accuracy: 0.9072 - val_loss: 0.2019\n",
      "Epoch 72/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9202 - loss: 0.1820 - val_accuracy: 0.9061 - val_loss: 0.2018\n",
      "Epoch 73/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9140 - loss: 0.1908 - val_accuracy: 0.9075 - val_loss: 0.2065\n",
      "Epoch 74/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9177 - loss: 0.1837 - val_accuracy: 0.9064 - val_loss: 0.2053\n",
      "Epoch 75/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9207 - loss: 0.1801 - val_accuracy: 0.9083 - val_loss: 0.2042\n",
      "Epoch 76/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9196 - loss: 0.1794 - val_accuracy: 0.9058 - val_loss: 0.2037\n",
      "Epoch 77/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9198 - loss: 0.1792 - val_accuracy: 0.9047 - val_loss: 0.2029\n",
      "Epoch 78/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9223 - loss: 0.1760 - val_accuracy: 0.9055 - val_loss: 0.2040\n",
      "Epoch 79/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9204 - loss: 0.1789 - val_accuracy: 0.9094 - val_loss: 0.2026\n",
      "Epoch 80/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9215 - loss: 0.1762 - val_accuracy: 0.9055 - val_loss: 0.2028\n",
      "Epoch 81/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9195 - loss: 0.1812 - val_accuracy: 0.9092 - val_loss: 0.2050\n",
      "Epoch 82/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9194 - loss: 0.1776 - val_accuracy: 0.9061 - val_loss: 0.2032\n",
      "Epoch 83/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1810 - val_accuracy: 0.9078 - val_loss: 0.2019\n",
      "Epoch 84/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9199 - loss: 0.1788 - val_accuracy: 0.9069 - val_loss: 0.2051\n",
      "Epoch 85/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9188 - loss: 0.1805 - val_accuracy: 0.9067 - val_loss: 0.2034\n",
      "Epoch 86/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9221 - loss: 0.1730 - val_accuracy: 0.9044 - val_loss: 0.2063\n",
      "Epoch 87/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9212 - loss: 0.1740 - val_accuracy: 0.9058 - val_loss: 0.2055\n",
      "Epoch 88/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9227 - loss: 0.1784 - val_accuracy: 0.9078 - val_loss: 0.2061\n",
      "Epoch 89/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9192 - loss: 0.1786 - val_accuracy: 0.9094 - val_loss: 0.2046\n",
      "Epoch 90/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9226 - loss: 0.1767 - val_accuracy: 0.9058 - val_loss: 0.2044\n",
      "Epoch 91/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9206 - loss: 0.1753 - val_accuracy: 0.9078 - val_loss: 0.2035\n",
      "Epoch 92/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9223 - loss: 0.1742 - val_accuracy: 0.9027 - val_loss: 0.2053\n",
      "Epoch 93/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9193 - loss: 0.1748 - val_accuracy: 0.9058 - val_loss: 0.2046\n",
      "Epoch 94/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9204 - loss: 0.1803 - val_accuracy: 0.9103 - val_loss: 0.2076\n",
      "Epoch 95/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9242 - loss: 0.1744 - val_accuracy: 0.9078 - val_loss: 0.2059\n",
      "Epoch 96/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9212 - loss: 0.1749 - val_accuracy: 0.9064 - val_loss: 0.2071\n",
      "Epoch 97/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9206 - loss: 0.1759 - val_accuracy: 0.9075 - val_loss: 0.2044\n",
      "Epoch 98/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9231 - loss: 0.1758 - val_accuracy: 0.9086 - val_loss: 0.2048\n",
      "Epoch 99/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9218 - loss: 0.1765 - val_accuracy: 0.9025 - val_loss: 0.2039\n",
      "Epoch 100/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9219 - loss: 0.1766 - val_accuracy: 0.9047 - val_loss: 0.2065\n",
      "\u001B[1m280/280\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Test Accuracy (CNN - 1 Conv Layer): 0.9105645612073784\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7931\n",
      "           1       0.66      0.43      0.52      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.80      0.70      0.74      8945\n",
      "weighted avg       0.90      0.91      0.90      8945\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7708  223]\n",
      " [ 577  437]]\n",
      "\n",
      "CNN (1 layer) model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# reshape data for CNN\n",
    "X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn  = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "model_cnn_1 = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(42, 1)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn_1.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_1 = model_cnn_1.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# evaluation\n",
    "y_pred_prob = model_cnn_1.predict(X_test_cnn)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Test Accuracy (CNN - 1 Conv Layer):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# save model\n",
    "model_cnn_1.save(\"cnn_1layer_100v1.h5\")\n",
    "print(\"\\nCNN (1 layer) model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f367c4fc-3593-4f76-b3fa-d215a3c8a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khank\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8832 - loss: 0.2922 - val_accuracy: 0.8971 - val_loss: 0.2267\n",
      "Epoch 2/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9036 - loss: 0.2213 - val_accuracy: 0.9002 - val_loss: 0.2184\n",
      "Epoch 3/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9039 - loss: 0.2131 - val_accuracy: 0.9025 - val_loss: 0.2137\n",
      "Epoch 4/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9047 - loss: 0.2153 - val_accuracy: 0.9016 - val_loss: 0.2118\n",
      "Epoch 5/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9057 - loss: 0.2156 - val_accuracy: 0.9016 - val_loss: 0.2099\n",
      "Epoch 6/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9086 - loss: 0.2096 - val_accuracy: 0.8999 - val_loss: 0.2083\n",
      "Epoch 7/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9088 - loss: 0.2069 - val_accuracy: 0.8997 - val_loss: 0.2091\n",
      "Epoch 8/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.9074 - loss: 0.2108 - val_accuracy: 0.9033 - val_loss: 0.2063\n",
      "Epoch 9/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.9096 - loss: 0.2044 - val_accuracy: 0.9030 - val_loss: 0.2057\n",
      "Epoch 10/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9084 - loss: 0.2039 - val_accuracy: 0.9016 - val_loss: 0.2061\n",
      "Epoch 11/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.9117 - loss: 0.2025 - val_accuracy: 0.9036 - val_loss: 0.2038\n",
      "Epoch 12/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.9108 - loss: 0.1970 - val_accuracy: 0.9033 - val_loss: 0.2037\n",
      "Epoch 13/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9110 - loss: 0.1983 - val_accuracy: 0.9044 - val_loss: 0.2030\n",
      "Epoch 14/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9125 - loss: 0.1982 - val_accuracy: 0.9050 - val_loss: 0.2035\n",
      "Epoch 15/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9131 - loss: 0.1953 - val_accuracy: 0.9044 - val_loss: 0.2029\n",
      "Epoch 16/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9108 - loss: 0.2002 - val_accuracy: 0.9002 - val_loss: 0.2042\n",
      "Epoch 17/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9127 - loss: 0.1927 - val_accuracy: 0.9041 - val_loss: 0.2019\n",
      "Epoch 18/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9094 - loss: 0.1987 - val_accuracy: 0.9030 - val_loss: 0.2030\n",
      "Epoch 19/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9143 - loss: 0.1910 - val_accuracy: 0.9067 - val_loss: 0.2028\n",
      "Epoch 20/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9121 - loss: 0.1957 - val_accuracy: 0.9033 - val_loss: 0.2019\n",
      "Epoch 21/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9163 - loss: 0.1887 - val_accuracy: 0.9008 - val_loss: 0.2019\n",
      "Epoch 22/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9115 - loss: 0.1940 - val_accuracy: 0.9039 - val_loss: 0.2016\n",
      "Epoch 23/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9125 - loss: 0.1926 - val_accuracy: 0.9013 - val_loss: 0.2041\n",
      "Epoch 24/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9119 - loss: 0.1891 - val_accuracy: 0.9019 - val_loss: 0.2023\n",
      "Epoch 25/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9137 - loss: 0.1864 - val_accuracy: 0.9033 - val_loss: 0.2009\n",
      "Epoch 26/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9146 - loss: 0.1913 - val_accuracy: 0.9044 - val_loss: 0.1995\n",
      "Epoch 27/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9138 - loss: 0.1875 - val_accuracy: 0.9030 - val_loss: 0.2017\n",
      "Epoch 28/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9172 - loss: 0.1857 - val_accuracy: 0.9033 - val_loss: 0.2104\n",
      "Epoch 29/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9162 - loss: 0.1896 - val_accuracy: 0.9016 - val_loss: 0.2020\n",
      "Epoch 30/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9147 - loss: 0.1908 - val_accuracy: 0.9036 - val_loss: 0.2019\n",
      "Epoch 31/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9139 - loss: 0.1876 - val_accuracy: 0.9011 - val_loss: 0.2024\n",
      "Epoch 32/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9122 - loss: 0.1899 - val_accuracy: 0.9050 - val_loss: 0.2028\n",
      "Epoch 33/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9161 - loss: 0.1846 - val_accuracy: 0.9019 - val_loss: 0.2024\n",
      "Epoch 34/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9160 - loss: 0.1833 - val_accuracy: 0.9047 - val_loss: 0.1991\n",
      "Epoch 35/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9196 - loss: 0.1796 - val_accuracy: 0.9033 - val_loss: 0.2044\n",
      "Epoch 36/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9162 - loss: 0.1841 - val_accuracy: 0.9055 - val_loss: 0.2014\n",
      "Epoch 37/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9174 - loss: 0.1824 - val_accuracy: 0.9050 - val_loss: 0.2024\n",
      "Epoch 38/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9198 - loss: 0.1786 - val_accuracy: 0.9030 - val_loss: 0.2059\n",
      "Epoch 39/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9177 - loss: 0.1781 - val_accuracy: 0.9041 - val_loss: 0.2032\n",
      "Epoch 40/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9183 - loss: 0.1788 - val_accuracy: 0.9025 - val_loss: 0.2014\n",
      "Epoch 41/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9199 - loss: 0.1754 - val_accuracy: 0.9033 - val_loss: 0.2043\n",
      "Epoch 42/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9206 - loss: 0.1788 - val_accuracy: 0.9080 - val_loss: 0.2094\n",
      "Epoch 43/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9247 - loss: 0.1736 - val_accuracy: 0.9044 - val_loss: 0.2038\n",
      "Epoch 44/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9198 - loss: 0.1738 - val_accuracy: 0.9067 - val_loss: 0.2053\n",
      "Epoch 45/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9247 - loss: 0.1705 - val_accuracy: 0.9058 - val_loss: 0.2052\n",
      "Epoch 46/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9236 - loss: 0.1728 - val_accuracy: 0.9041 - val_loss: 0.2036\n",
      "Epoch 47/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9207 - loss: 0.1714 - val_accuracy: 0.9041 - val_loss: 0.2061\n",
      "Epoch 48/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9201 - loss: 0.1721 - val_accuracy: 0.9027 - val_loss: 0.2081\n",
      "Epoch 49/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9209 - loss: 0.1748 - val_accuracy: 0.9058 - val_loss: 0.2065\n",
      "Epoch 50/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9227 - loss: 0.1702 - val_accuracy: 0.9069 - val_loss: 0.2085\n",
      "Epoch 51/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9228 - loss: 0.1700 - val_accuracy: 0.9039 - val_loss: 0.2147\n",
      "Epoch 52/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9218 - loss: 0.1700 - val_accuracy: 0.9075 - val_loss: 0.2075\n",
      "Epoch 53/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9240 - loss: 0.1694 - val_accuracy: 0.9039 - val_loss: 0.2093\n",
      "Epoch 54/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9224 - loss: 0.1673 - val_accuracy: 0.9055 - val_loss: 0.2108\n",
      "Epoch 55/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9235 - loss: 0.1658 - val_accuracy: 0.9055 - val_loss: 0.2132\n",
      "Epoch 56/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9245 - loss: 0.1704 - val_accuracy: 0.9058 - val_loss: 0.2117\n",
      "Epoch 57/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9220 - loss: 0.1711 - val_accuracy: 0.9069 - val_loss: 0.2076\n",
      "Epoch 58/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9231 - loss: 0.1681 - val_accuracy: 0.9055 - val_loss: 0.2100\n",
      "Epoch 59/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9230 - loss: 0.1688 - val_accuracy: 0.9055 - val_loss: 0.2139\n",
      "Epoch 60/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9262 - loss: 0.1653 - val_accuracy: 0.9041 - val_loss: 0.2119\n",
      "Epoch 61/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9219 - loss: 0.1694 - val_accuracy: 0.9097 - val_loss: 0.2108\n",
      "Epoch 62/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9234 - loss: 0.1669 - val_accuracy: 0.9053 - val_loss: 0.2167\n",
      "Epoch 63/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9238 - loss: 0.1650 - val_accuracy: 0.9041 - val_loss: 0.2132\n",
      "Epoch 64/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9252 - loss: 0.1657 - val_accuracy: 0.9067 - val_loss: 0.2179\n",
      "Epoch 65/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9253 - loss: 0.1639 - val_accuracy: 0.9061 - val_loss: 0.2120\n",
      "Epoch 66/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9223 - loss: 0.1670 - val_accuracy: 0.9083 - val_loss: 0.2136\n",
      "Epoch 67/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9233 - loss: 0.1710 - val_accuracy: 0.9041 - val_loss: 0.2160\n",
      "Epoch 68/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9258 - loss: 0.1640 - val_accuracy: 0.9080 - val_loss: 0.2178\n",
      "Epoch 69/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9243 - loss: 0.1649 - val_accuracy: 0.9044 - val_loss: 0.2150\n",
      "Epoch 70/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9274 - loss: 0.1623 - val_accuracy: 0.9053 - val_loss: 0.2231\n",
      "Epoch 71/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9265 - loss: 0.1615 - val_accuracy: 0.9075 - val_loss: 0.2153\n",
      "Epoch 72/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9258 - loss: 0.1625 - val_accuracy: 0.9069 - val_loss: 0.2115\n",
      "Epoch 73/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9277 - loss: 0.1592 - val_accuracy: 0.9044 - val_loss: 0.2204\n",
      "Epoch 74/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9247 - loss: 0.1624 - val_accuracy: 0.9078 - val_loss: 0.2164\n",
      "Epoch 75/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9276 - loss: 0.1583 - val_accuracy: 0.9064 - val_loss: 0.2243\n",
      "Epoch 76/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9265 - loss: 0.1608 - val_accuracy: 0.9103 - val_loss: 0.2156\n",
      "Epoch 77/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9268 - loss: 0.1620 - val_accuracy: 0.9075 - val_loss: 0.2213\n",
      "Epoch 78/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9294 - loss: 0.1568 - val_accuracy: 0.9069 - val_loss: 0.2211\n",
      "Epoch 79/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9254 - loss: 0.1624 - val_accuracy: 0.9058 - val_loss: 0.2158\n",
      "Epoch 80/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9252 - loss: 0.1639 - val_accuracy: 0.9064 - val_loss: 0.2186\n",
      "Epoch 81/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9274 - loss: 0.1578 - val_accuracy: 0.9072 - val_loss: 0.2241\n",
      "Epoch 82/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9278 - loss: 0.1573 - val_accuracy: 0.9086 - val_loss: 0.2253\n",
      "Epoch 83/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9286 - loss: 0.1581 - val_accuracy: 0.9058 - val_loss: 0.2297\n",
      "Epoch 84/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9287 - loss: 0.1588 - val_accuracy: 0.9050 - val_loss: 0.2325\n",
      "Epoch 85/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9302 - loss: 0.1575 - val_accuracy: 0.9030 - val_loss: 0.2285\n",
      "Epoch 86/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9286 - loss: 0.1560 - val_accuracy: 0.9030 - val_loss: 0.2269\n",
      "Epoch 87/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9274 - loss: 0.1550 - val_accuracy: 0.9058 - val_loss: 0.2346\n",
      "Epoch 88/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9295 - loss: 0.1591 - val_accuracy: 0.9050 - val_loss: 0.2306\n",
      "Epoch 89/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9293 - loss: 0.1554 - val_accuracy: 0.9033 - val_loss: 0.2319\n",
      "Epoch 90/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9270 - loss: 0.1563 - val_accuracy: 0.9039 - val_loss: 0.2298\n",
      "Epoch 91/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9240 - loss: 0.1604 - val_accuracy: 0.9011 - val_loss: 0.2311\n",
      "Epoch 92/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9269 - loss: 0.1545 - val_accuracy: 0.9022 - val_loss: 0.2337\n",
      "Epoch 93/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9274 - loss: 0.1512 - val_accuracy: 0.9039 - val_loss: 0.2353\n",
      "Epoch 94/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9304 - loss: 0.1553 - val_accuracy: 0.9016 - val_loss: 0.2395\n",
      "Epoch 95/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9286 - loss: 0.1563 - val_accuracy: 0.9044 - val_loss: 0.2362\n",
      "Epoch 96/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9310 - loss: 0.1541 - val_accuracy: 0.9016 - val_loss: 0.2392\n",
      "Epoch 97/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9289 - loss: 0.1511 - val_accuracy: 0.9041 - val_loss: 0.2347\n",
      "Epoch 98/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9301 - loss: 0.1494 - val_accuracy: 0.8999 - val_loss: 0.2348\n",
      "Epoch 99/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.9329 - loss: 0.1525 - val_accuracy: 0.9036 - val_loss: 0.2363\n",
      "Epoch 100/100\n",
      "\u001B[1m504/504\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.9335 - loss: 0.1471 - val_accuracy: 0.9036 - val_loss: 0.2411\n",
      "\u001B[1m280/280\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n",
      "Test Accuracy (CNN - 2 Conv Layers): 0.9073225265511459\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7931\n",
      "           1       0.63      0.44      0.52      1014\n",
      "\n",
      "    accuracy                           0.91      8945\n",
      "   macro avg       0.78      0.70      0.73      8945\n",
      "weighted avg       0.90      0.91      0.90      8945\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7668  263]\n",
      " [ 566  448]]\n",
      "\n",
      "CNN (2 layers) model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "model_cnn_2 = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(42, 1)),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn_2.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_2 = model_cnn_2.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# evaluation\n",
    "y_pred_prob = model_cnn_2.predict(X_test_cnn)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Test Accuracy (CNN - 2 Conv Layers):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# save model\n",
    "model_cnn_2.save(\"cnn_2layer_100v1.h5\")\n",
    "print(\"\\nCNN (2 layers) model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19903cc5-3377-4a79-b817-31f1efa45f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test dataset with labels saved successfully.\n",
      "Shape: (8945, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>pdays_contacted</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.450810</td>\n",
       "      <td>0.406207</td>\n",
       "      <td>-0.097627</td>\n",
       "      <td>1.233235</td>\n",
       "      <td>0.488541</td>\n",
       "      <td>0.350587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.157084</td>\n",
       "      <td>-0.435734</td>\n",
       "      <td>-1.659240</td>\n",
       "      <td>-0.207087</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.355330</td>\n",
       "      <td>-0.556075</td>\n",
       "      <td>-0.938495</td>\n",
       "      <td>-0.398846</td>\n",
       "      <td>-0.645438</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.457742</td>\n",
       "      <td>-0.824941</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>0.282963</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747082</td>\n",
       "      <td>-0.554286</td>\n",
       "      <td>-0.457999</td>\n",
       "      <td>0.244612</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>-0.363878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   balance       day  duration  campaign  previous  \\\n",
       "0  2.450810  0.406207 -0.097627  1.233235  0.488541  0.350587   \n",
       "1 -1.157084 -0.435734 -1.659240 -0.207087  0.110548 -0.363878   \n",
       "2 -0.355330 -0.556075 -0.938495 -0.398846 -0.645438 -0.363878   \n",
       "3 -1.457742 -0.824941  0.022497  0.282963  0.110548 -0.363878   \n",
       "4  0.747082 -0.554286 -0.457999  0.244612  0.110548 -0.363878   \n",
       "\n",
       "   pdays_contacted  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
       "0                1                0                 0              0  ...   \n",
       "1                0                0                 1              0  ...   \n",
       "2                0                0                 0              0  ...   \n",
       "3                0                1                 0              0  ...   \n",
       "4                0                0                 0              1  ...   \n",
       "\n",
       "   month_jun  month_mar  month_may  month_nov  month_oct  month_sep  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          1          0          0          0          0          0   \n",
       "2          0          0          1          0          0          0   \n",
       "3          0          0          1          0          0          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  y  \n",
       "0               0                 0                 0  0  \n",
       "1               0                 0                 1  0  \n",
       "2               0                 0                 1  0  \n",
       "3               0                 0                 1  0  \n",
       "4               0                 0                 1  0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Test Set with Labels to CSV\n",
    "\n",
    "# Combine X_test and y_test\n",
    "test_with_labels = X_test.copy()\n",
    "test_with_labels['y'] = y_test.values\n",
    "\n",
    "# Reset index for clean CSV\n",
    "test_with_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "test_with_labels.to_csv(\n",
    "    'bank_marketing_test_set.csv',\n",
    "    index=False,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(\"✅ Test dataset with labels saved successfully.\")\n",
    "print(\"Shape:\", test_with_labels.shape)\n",
    "\n",
    "display(test_with_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb3775-07d8-4444-9345-e707b6e8006e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
